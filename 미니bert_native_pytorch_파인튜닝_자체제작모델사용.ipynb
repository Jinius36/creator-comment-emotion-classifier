{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5yKUmHEYa8i",
        "outputId": "b09dbbeb-9c51-4711-9e1c-9759ec83f7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Colab에 필요한 라이브러리를 설치합니다.\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68RNgOPVYfbg",
        "outputId": "557239ac-d33a-46f7-81f7-2fcafb756549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n",
            "라벨 종류: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 1. 데이터셋 로드\n",
        "# train, validation, test 세트로 구성된 것을 확인할 수 있습니다.\n",
        "datasets = load_dataset(\"dair-ai/emotion\")\n",
        "print(datasets)\n",
        "\n",
        "# 2. 라벨 이름 확인 (참고)\n",
        "# 0: sadness, 1: joy, 2: love, 3: anger, 4: fear, 5: surprise\n",
        "label_names = datasets[\"train\"].features[\"label\"].names\n",
        "print(f\"라벨 종류: {label_names}\")\n",
        "\n",
        "# - 라벨 개수를 따로 저장해 이후 셀에서 재사용한다\n",
        "num_labels = len(label_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSMkvw941jBY",
        "outputId": "a8cc5941-ac7f-4710-9c4b-52309c7e3415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용할 장치: cuda\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# - 실험 재현을 위해 모든 모듈 시드를 고정한다\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# - 학습에 사용할 디바이스 정보를 미리 출력한다\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용할 장치: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "REPO=https://github.com/Jinius36/creator-comment-emotion-classifier.git\n",
        "DIR=/content/creator-comment-emotion-classifier\n",
        "\n",
        "if [ -d \"$DIR/.git\" ]; then\n",
        "  git -C \"$DIR\" remote set-url origin \"$REPO\"\n",
        "  git -C \"$DIR\" fetch origin\n",
        "  DEFAULT_BRANCH=$(git -C \"$DIR\" symbolic-ref --short refs/remotes/origin/HEAD | cut -d'/' -f2)\n",
        "  git -C \"$DIR\" checkout \"$DEFAULT_BRANCH\"\n",
        "  git -C \"$DIR\" reset --hard \"origin/$DEFAULT_BRANCH\"\n",
        "else\n",
        "  git clone \"$REPO\" \"$DIR\"\n",
        "fi\n",
        "echo \"[ok] synced: $DIR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ieiZxNqKEHd",
        "outputId": "282327b0-78f1-4d03-fb16-0ca7bbb4878b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your branch is up to date with 'origin/main'.\n",
            "HEAD is now at 6a6d1b9 Merge pull request #4 from Jinius36/leekwanjin\n",
            "[ok] synced: /content/creator-comment-emotion-classifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "From https://github.com/Jinius36/creator-comment-emotion-classifier\n",
            "   32d5908..b618f55  Chung      -> origin/Chung\n",
            "Already on 'main'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PRETRAINED_FILE_PATH = \"./bert-implementation/colab/pre-trained-model/save_bert_pretrain.pth\"\n",
        "VOCAB_FILE = \"./data-preprocessing/mini_emotion_tokenizer_7k.txt\"\n",
        "\n",
        "assert os.path.exists(PRETRAINED_FILE_PATH), f\"not found: {PRETRAINED_FILE_PATH}\"\n",
        "assert os.path.exists(VOCAB_FILE), f\"not found: {VOCAB_FILE}\"\n",
        "\n",
        "print(\"[OK] ckpt:\", os.path.abspath(PRETRAINED_FILE_PATH))\n",
        "print(\"[OK] vocab:\", os.path.abspath(VOCAB_FILE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1mawMygKEWx",
        "outputId": "16200778-1804-4cb6-a7dc-0e8392322018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ckpt: /content/creator-comment-emotion-classifier/bert-implementation/colab/pre-trained-model/save_bert_pretrain.pth\n",
            "[OK] vocab: /content/creator-comment-emotion-classifier/data-preprocessing/mini_emotion_tokenizer_7k.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8KzUvdXe1jBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334c137a-8d2d-489d-dae7-34fac4974a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fine-tune 설정 ===\n",
            "epochs: 3\n",
            "train_batch_size: 32\n",
            "eval_batch_size: 32\n",
            "learning_rate: 5e-05\n",
            "pretrained_path: ./bert-implementation/colab/pre-trained-model/save_bert_pretrain.pth\n",
            "num_labels: 6\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# --- 1. 학습 설정 (Hyperparameters) ---\n",
        "# - 학습 관련 핵심 값을 한 곳에서 정의한다\n",
        "NUM_EPOCHS = 3\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-5\n",
        "# PRETRAINED_FILE_PATH = \"./save_bert_pretrain.pth\"- (수정 by 승연.) github로부터 load.\n",
        "\n",
        "# - 실행 전에 설정을 한눈에 점검한다\n",
        "def describe_run():\n",
        "    print(\"=== Fine-tune 설정 ===\")\n",
        "    print(f\"epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"train_batch_size: {TRAIN_BATCH_SIZE}\")\n",
        "    print(f\"eval_batch_size: {EVAL_BATCH_SIZE}\")\n",
        "    print(f\"learning_rate: {LEARNING_RATE}\")\n",
        "    print(f\"pretrained_path: {PRETRAINED_FILE_PATH}\")\n",
        "    print(f\"num_labels: {num_labels}\")\n",
        "    print(f\"device: {DEVICE}\")\n",
        "\n",
        "describe_run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fh80j6iy1jBZ"
      },
      "outputs": [],
      "source": [
        "# 팀원의 bert_implementation.ipynb에서 가져온 핵심 Config 및 모듈 정의\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Config(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)\n",
        "\n",
        "def create_padding_mask(seq_q, seq_k, pad_idx):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    mask = seq_k.eq(pad_idx).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return mask\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.scale = 1 / (config.d_head ** 0.5)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) * self.scale\n",
        "        scores.masked_fill_(mask, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.W_Q = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.W_K = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.W_V = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.scaled_attn = ScaledDotProductAttention(config)\n",
        "        self.linear = nn.Linear(config.n_head * config.d_head, config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask):\n",
        "        B = Q.size(0)\n",
        "        q_s = self.W_Q(Q).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        k_s = self.W_K(K).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        v_s = self.W_V(V).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        mask = mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "        context, attn = self.scaled_attn(q_s, k_s, v_s, mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, -1, self.config.n_head * self.config.d_head)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(config.d_hidn, config.d_ff)\n",
        "        self.linear2 = nn.Linear(config.d_ff, config.d_hidn)\n",
        "        self.activation = nn.GELU()\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "\n",
        "class SelfAttentionEncoderBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.multi_head_attn = MultiHeadSelfAttention(config)\n",
        "        self.norm_after_attn = nn.LayerNorm(config.d_hidn, eps=config.layer_norm_epsilon)\n",
        "        self.feed_forward = PositionwiseFeedForward(config)\n",
        "        self.norm_after_ffn = nn.LayerNorm(config.d_hidn, eps=config.layer_norm_epsilon)\n",
        "\n",
        "    def forward(self, x, attn_mask):\n",
        "        attn_output, attn_weights = self.multi_head_attn(x, x, x, attn_mask)\n",
        "        x = self.norm_after_attn(x + attn_output)\n",
        "        ffn_output = self.feed_forward(x)\n",
        "        x = self.norm_after_ffn(x + ffn_output)\n",
        "        return x, attn_weights\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding = nn.Embedding(config.n_enc_vocab, config.d_hidn)\n",
        "        self.position_embedding = nn.Embedding(config.n_enc_seq + 1, config.d_hidn)\n",
        "        self.segment_embedding = nn.Embedding(config.n_seg_type, config.d_hidn)\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            SelfAttentionEncoderBlock(config) for _ in range(config.n_layer)\n",
        "        ])\n",
        "\n",
        "    def forward(self, token_ids, segment_ids):\n",
        "        seq_length = token_ids.size(1)\n",
        "        device = token_ids.device\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=device).unsqueeze(0).expand_as(token_ids) + 1\n",
        "        position_ids = position_ids.masked_fill(token_ids.eq(self.config.i_pad), 0)\n",
        "        x = (\n",
        "            self.token_embedding(token_ids)\n",
        "            + self.position_embedding(position_ids)\n",
        "            + self.segment_embedding(segment_ids)\n",
        "        )\n",
        "        attn_mask = create_padding_mask(token_ids, token_ids, self.config.i_pad)\n",
        "        all_attention_weights = []\n",
        "        for block in self.encoder_blocks:\n",
        "            x, attn_weights = block(x, attn_mask)\n",
        "            all_attention_weights.append(attn_weights)\n",
        "        return x, all_attention_weights\n",
        "\n",
        "class BERTModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.encoder = TransformerEncoder(self.config)\n",
        "        self.linear_cls = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation_cls = torch.tanh\n",
        "\n",
        "    def forward(self, input_ids, segment_ids):\n",
        "        encoder_output, attention_weights = self.encoder(input_ids, segment_ids)\n",
        "        cls_output = encoder_output[:, 0].contiguous()\n",
        "        cls_output = self.linear_cls(cls_output)\n",
        "        cls_output = self.activation_cls(cls_output)\n",
        "        return encoder_output, cls_output, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_O4TG78UYln0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "4333d43f-51db-4573-ecfa-2c1e3c38f2c3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1992\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m                         resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1994\u001b[0m                             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         resolved_files = [\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-646419232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVOCAB_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m                         \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m                         raise OSError(\n\u001b[0m\u001b[1;32m   2014\u001b[0m                             \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m                             \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer."
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer  # AutoTokenizer 대신 명시적으로 사용\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(VOCAB_FILE, do_lower_case=True)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "print(\"커스텀 7k 토크나이저 로드 완료\")\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "print(\"전처리 후 데이터 샘플:\")\n",
        "print(tokenized_datasets[\"train\"][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JSElb6SYrzF"
      },
      "outputs": [],
      "source": [
        "class BERTForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = BERTModel(config)\n",
        "        self.classifier = nn.Linear(config.d_hidn, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, segment_ids):\n",
        "        _, cls_output, _ = self.bert(input_ids, segment_ids)\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits\n",
        "\n",
        "print(\"BERTForSequenceClassification 정의 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mjSrWxpY11R"
      },
      "outputs": [],
      "source": [
        "# --- 2. ⚠️ 팀의 BERT 모델 로드 ⚠️ ---\n",
        "# - 사전학습 구성으로 BERT 분류 모델을 초기화한다\n",
        "config = Config({\n",
        "    \"n_enc_vocab\": 7000,\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "config.device = DEVICE\n",
        "\n",
        "model = BERTForSequenceClassification(config, num_labels=num_labels).to(DEVICE)\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(PRETRAINED_FILE_PATH, map_location=DEVICE)\n",
        "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
        "    model.bert.load_state_dict(state_dict)\n",
        "    print(f\"[불러오기 완료] '{PRETRAINED_FILE_PATH}' 로드 성공\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[경고] '{PRETRAINED_FILE_PATH}' 파일을 찾지 못했습니다. 경로를 확인하세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"[오류] 모델 로드 실패: {e}\")\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# - 데이터 분할별 배치 크기를 적용해 DataLoader를 만든다\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
        "eval_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=EVAL_BATCH_SIZE)\n",
        "print(\"모델, 옵티마이저, 데이터로더 준비 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxCJuCO2ZOkr"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# - 지정한 에포크 동안 학습과 검증을 반복한다\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\n",
        "--- Epoch {epoch + 1}/{NUM_EPOCHS} ---\")\n",
        "    # --- 1. 학습 (Training) ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "        segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_dataloader)\n",
        "    print(f\"평균 학습 손실(Loss): {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- 2. 평가 (Validation) ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Validation\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "            logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "            loss = criterion(logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(eval_dataloader)\n",
        "    accuracy = correct_predictions / len(tokenized_datasets[\"validation\"])\n",
        "    print(f\"평균 검증 손실(Loss): {avg_val_loss:.4f} | 정확도: {accuracy:.4f}\")\n",
        "\n",
        "print(\"--- 학습 완료! ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYqIliEjZQF-"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_emotion(text):\n",
        "    print(f'입력 문장: \"{text}\"')\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    input_ids = inputs[\"input_ids\"].to(DEVICE)\n",
        "    segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "\n",
        "    probabilities = F.softmax(logits, dim=1)[0]\n",
        "    results = {label: probabilities[i].item() for i, label in enumerate(label_names)}\n",
        "\n",
        "    print(\"--- 6개 라벨 Softmax 확률 값 ---\")\n",
        "    for label, prob in results.items():\n",
        "        print(f\"{label:10}: {prob:.4f} ( {prob*100:6.2f} % )\")\n",
        "\n",
        "    predicted_label_index = torch.argmax(probabilities).item()\n",
        "    predicted_label = label_names[predicted_label_index]\n",
        "    print(f\"\\\\n=> 예측된 감정: {predicted_label}\")\n",
        "\n",
        "predict_emotion(\"I feel so happy and excited today!\")\n",
        "print(\"-\" * 30)\n",
        "predict_emotion(\"This is so frustrating and makes me angry.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}