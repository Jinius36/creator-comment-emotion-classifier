{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jinius36/creator-comment-emotion-classifier.git\n",
        "%cd /content/<REPO>\n",
        "\n",
        "# LFS 파일(.pth 등) 있으면\n",
        "!sudo apt-get -y install git-lfs\n",
        "!git lfs install\n",
        "!git lfs pull\n",
        "!ls -lah\n"
      ],
      "metadata": {
        "id": "IB4Eb67n2FVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5yKUmHEYa8i"
      },
      "outputs": [],
      "source": [
        "# Colab에 필요한 라이브러리를 설치합니다.\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68RNgOPVYfbg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 1. 데이터셋 로드\n",
        "# train, validation, test 세트로 구성된 것을 확인할 수 있습니다.\n",
        "datasets = load_dataset(\"dair-ai/emotion\")\n",
        "print(datasets)\n",
        "\n",
        "# 2. 라벨 이름 확인 (참고)\n",
        "# 0: sadness, 1: joy, 2: love, 3: anger, 4: fear, 5: surprise\n",
        "label_names = datasets[\"train\"].features[\"label\"].names\n",
        "print(f\"라벨 종류: {label_names}\")\n",
        "\n",
        "# - 라벨 개수를 따로 저장해 이후 셀에서 재사용한다\n",
        "num_labels = len(label_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSMkvw941jBY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# - 실험 재현을 위해 모든 모듈 시드를 고정한다\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# - 학습에 사용할 디바이스 정보를 미리 출력한다\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용할 장치: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KzUvdXe1jBZ"
      },
      "outputs": [],
      "source": [
        "# --- 1. 학습 설정 (Hyperparameters) ---\n",
        "# - 학습 관련 핵심 값을 한 곳에서 정의한다\n",
        "NUM_EPOCHS = 3\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-5\n",
        "PRETRAINED_FILE_PATH = \"./save_bert_pretrain.pth\"\n",
        "\n",
        "# - 실행 전에 설정을 한눈에 점검한다\n",
        "def describe_run():\n",
        "    print(\"=== Fine-tune 설정 ===\")\n",
        "    print(f\"epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"train_batch_size: {TRAIN_BATCH_SIZE}\")\n",
        "    print(f\"eval_batch_size: {EVAL_BATCH_SIZE}\")\n",
        "    print(f\"learning_rate: {LEARNING_RATE}\")\n",
        "    print(f\"pretrained_path: {PRETRAINED_FILE_PATH}\")\n",
        "    print(f\"num_labels: {num_labels}\")\n",
        "    print(f\"device: {DEVICE}\")\n",
        "\n",
        "describe_run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh80j6iy1jBZ"
      },
      "outputs": [],
      "source": [
        "# 팀원의 bert_implementation.ipynb에서 가져온 핵심 Config 및 모듈 정의\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Config(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)\n",
        "\n",
        "def create_padding_mask(seq_q, seq_k, pad_idx):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    mask = seq_k.eq(pad_idx).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return mask\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.scale = 1 / (config.d_head ** 0.5)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) * self.scale\n",
        "        scores.masked_fill_(mask, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.W_Q = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.W_K = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.W_V = nn.Linear(config.d_hidn, config.n_head * config.d_head)\n",
        "        self.scaled_attn = ScaledDotProductAttention(config)\n",
        "        self.linear = nn.Linear(config.n_head * config.d_head, config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, mask):\n",
        "        B = Q.size(0)\n",
        "        q_s = self.W_Q(Q).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        k_s = self.W_K(K).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        v_s = self.W_V(V).view(B, -1, self.config.n_head, self.config.d_head).transpose(1, 2)\n",
        "        mask = mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "        context, attn = self.scaled_attn(q_s, k_s, v_s, mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, -1, self.config.n_head * self.config.d_head)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(config.d_hidn, config.d_ff)\n",
        "        self.linear2 = nn.Linear(config.d_ff, config.d_hidn)\n",
        "        self.activation = nn.GELU()\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "\n",
        "class SelfAttentionEncoderBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.multi_head_attn = MultiHeadSelfAttention(config)\n",
        "        self.norm_after_attn = nn.LayerNorm(config.d_hidn, eps=config.layer_norm_epsilon)\n",
        "        self.feed_forward = PositionwiseFeedForward(config)\n",
        "        self.norm_after_ffn = nn.LayerNorm(config.d_hidn, eps=config.layer_norm_epsilon)\n",
        "\n",
        "    def forward(self, x, attn_mask):\n",
        "        attn_output, attn_weights = self.multi_head_attn(x, x, x, attn_mask)\n",
        "        x = self.norm_after_attn(x + attn_output)\n",
        "        ffn_output = self.feed_forward(x)\n",
        "        x = self.norm_after_ffn(x + ffn_output)\n",
        "        return x, attn_weights\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding = nn.Embedding(config.n_enc_vocab, config.d_hidn)\n",
        "        self.position_embedding = nn.Embedding(config.n_enc_seq + 1, config.d_hidn)\n",
        "        self.segment_embedding = nn.Embedding(config.n_seg_type, config.d_hidn)\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            SelfAttentionEncoderBlock(config) for _ in range(config.n_layer)\n",
        "        ])\n",
        "\n",
        "    def forward(self, token_ids, segment_ids):\n",
        "        seq_length = token_ids.size(1)\n",
        "        device = token_ids.device\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=device).unsqueeze(0).expand_as(token_ids) + 1\n",
        "        position_ids = position_ids.masked_fill(token_ids.eq(self.config.i_pad), 0)\n",
        "        x = (\n",
        "            self.token_embedding(token_ids)\n",
        "            + self.position_embedding(position_ids)\n",
        "            + self.segment_embedding(segment_ids)\n",
        "        )\n",
        "        attn_mask = create_padding_mask(token_ids, token_ids, self.config.i_pad)\n",
        "        all_attention_weights = []\n",
        "        for block in self.encoder_blocks:\n",
        "            x, attn_weights = block(x, attn_mask)\n",
        "            all_attention_weights.append(attn_weights)\n",
        "        return x, all_attention_weights\n",
        "\n",
        "class BERTModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.encoder = TransformerEncoder(self.config)\n",
        "        self.linear_cls = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation_cls = torch.tanh\n",
        "\n",
        "    def forward(self, input_ids, segment_ids):\n",
        "        encoder_output, attention_weights = self.encoder(input_ids, segment_ids)\n",
        "        cls_output = encoder_output[:, 0].contiguous()\n",
        "        cls_output = self.linear_cls(cls_output)\n",
        "        cls_output = self.activation_cls(cls_output)\n",
        "        return encoder_output, cls_output, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O4TG78UYln0"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer  # AutoTokenizer 대신 명시적으로 사용\n",
        "\n",
        "VOCAB_FILE = \"./bert-implementation/data-preprocessing/mini_emotion_tokenizer_7k.txt\"\n",
        "tokenizer = BertTokenizer.from_pretrained(VOCAB_FILE, do_lower_case=True)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "print(\"커스텀 7k 토크나이저 로드 완료\")\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "print(\"전처리 후 데이터 샘플:\")\n",
        "print(tokenized_datasets[\"train\"][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JSElb6SYrzF"
      },
      "outputs": [],
      "source": [
        "class BERTForSequenceClassification(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = BERTModel(config)\n",
        "        self.classifier = nn.Linear(config.d_hidn, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, segment_ids):\n",
        "        _, cls_output, _ = self.bert(input_ids, segment_ids)\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits\n",
        "\n",
        "print(\"BERTForSequenceClassification 정의 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mjSrWxpY11R"
      },
      "outputs": [],
      "source": [
        "# --- 2. ⚠️ 팀의 BERT 모델 로드 ⚠️ ---\n",
        "# - 사전학습 구성으로 BERT 분류 모델을 초기화한다\n",
        "config = Config({\n",
        "    \"n_enc_vocab\": 7000,\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "config.device = DEVICE\n",
        "\n",
        "model = BERTForSequenceClassification(config, num_labels=num_labels).to(DEVICE)\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(PRETRAINED_FILE_PATH, map_location=DEVICE)\n",
        "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
        "    model.bert.load_state_dict(state_dict)\n",
        "    print(f\"[불러오기 완료] '{PRETRAINED_FILE_PATH}' 로드 성공\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[경고] '{PRETRAINED_FILE_PATH}' 파일을 찾지 못했습니다. 경로를 확인하세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"[오류] 모델 로드 실패: {e}\")\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# - 데이터 분할별 배치 크기를 적용해 DataLoader를 만든다\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
        "eval_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=EVAL_BATCH_SIZE)\n",
        "print(\"모델, 옵티마이저, 데이터로더 준비 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxCJuCO2ZOkr"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# - 지정한 에포크 동안 학습과 검증을 반복한다\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\n",
        "--- Epoch {epoch + 1}/{NUM_EPOCHS} ---\")\n",
        "    # --- 1. 학습 (Training) ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "        segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_dataloader)\n",
        "    print(f\"평균 학습 손실(Loss): {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- 2. 평가 (Validation) ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Validation\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "            logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "            loss = criterion(logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(eval_dataloader)\n",
        "    accuracy = correct_predictions / len(tokenized_datasets[\"validation\"])\n",
        "    print(f\"평균 검증 손실(Loss): {avg_val_loss:.4f} | 정확도: {accuracy:.4f}\")\n",
        "\n",
        "print(\"--- 학습 완료! ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYqIliEjZQF-"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_emotion(text):\n",
        "    print(f'입력 문장: \"{text}\"')\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    input_ids = inputs[\"input_ids\"].to(DEVICE)\n",
        "    segment_ids = torch.zeros_like(input_ids).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids=input_ids, segment_ids=segment_ids)\n",
        "\n",
        "    probabilities = F.softmax(logits, dim=1)[0]\n",
        "    results = {label: probabilities[i].item() for i, label in enumerate(label_names)}\n",
        "\n",
        "    print(\"--- 6개 라벨 Softmax 확률 값 ---\")\n",
        "    for label, prob in results.items():\n",
        "        print(f\"{label:10}: {prob:.4f} ( {prob*100:6.2f} % )\")\n",
        "\n",
        "    predicted_label_index = torch.argmax(probabilities).item()\n",
        "    predicted_label = label_names[predicted_label_index]\n",
        "    print(f\"\\\\n=> 예측된 감정: {predicted_label}\")\n",
        "\n",
        "predict_emotion(\"I feel so happy and excited today!\")\n",
        "print(\"-\" * 30)\n",
        "predict_emotion(\"This is so frustrating and makes me angry.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}