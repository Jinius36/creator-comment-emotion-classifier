자기 전 중간보고 : 준성님이 올려주신건 Pre-Train 부분이 빠져있길래 저는 bert-uncased를 구조만 가져오고 새로 pre-train시켰습니다. 첫번째 사진이 그 결과입니다. 이걸 이용해서 default fine-tuning을 해본 결과, 준성님의 결과가 0.4 로 시작했던 것과 다르게 준수한 Accurancy를 보이는 것을 확인할 수 있었습니다. 

준성님이 올려주신 코드가 정확도가 낮게 나오던 이유는 bert의 vocab과 fine-tuning용 vocab 의 불일치가 원인입니다.

이를 바탕으로 더 나은 fine-tuning hyper parameter를 찾기 위해 전에 사용했던 F1-Macro Screening 방식을 사용해서, 72개 조합중 랜덤 24를 뽑아서 1epoch씩 훈련시키고 있습니다. 
이후 최선의 조합을 뽑아서 준성님의 default랑 같이 둘 다 validation loss 가 유의미한 변화를 보이지 않을 때까지 epoch를 반복할 예정입니다. 

+++
이번 pre-train된 Mini-BERT 모델이 기존 bert-uncased 대비 훨씬 안정적인 성능을 보였기 때문에, 여기에 맞는 fine-tuning 하이퍼파라미터를 다시 찾을 필요가 있었다. 전체 72개 조합을 모두 돌리는 것은 비효율적이라서, 우선 균등한 랜덤 방식으로 24개 조합만 추출해 1 epoch씩 간단하게 스크리닝을 했다. 이렇게 하면 탐색 비용을 크게 줄이면서도 다양한 조합을 공평하게 비교할 수 있기 때문에 초기 하이퍼파라미터 후보군을 좁히는 데 효과적이다.

스크리닝 결과를 바탕으로는 성능이 가장 높았던 조합 하나뿐만 아니라, 상위 5개 조합에서 공통적으로 등장한 값들을 기반으로 한 조합도 함께 선정했다. 하나는 단순히 점수가 제일 높은 방향이고, 다른 하나는 여러 조합에서 반복적으로 나타나는 안정적인 선택을 반영한 방향이라서, 두 모델 모두를 후보로 두는 것이 합리적이라고 판단했다.

이후에는 두 모델을 모두 긴 epoch 동안 학습시키되, validation 성능이 최고였던 epoch의 모델을 자동으로 선택하도록 구성했다. 이렇게 하면 과소적합이나 과대적합 없이 데이터에 가장 잘 맞는 지점을 스스로 찾게 되고, 최종적으로 두 모델 중 어떤 쪽이 더 우수한지 명확하게 비교할 수 있다.